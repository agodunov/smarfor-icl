{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aedfaac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "#import torchvision\n",
    "#import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f13502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to recreate the datase, uncomment the next line\n",
    "#%run create_dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd5d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_excel('dataset.xlsx', parse_dates=[0], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f8eeaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last two columns in data set are the real future data to be predicted\n",
    "X_ = ds.iloc[:,:-2].values\n",
    "# The last by one column is a value to be predicted\n",
    "y_ = ds.iloc[:,-2].values * 100 # Prediction scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5694687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y[y == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "742bce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c488b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75876303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader\n",
    "#ds_train = TensorDataset(X, y)\n",
    "#train_loader = DataLoader(ds_train, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f87179f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c20b04fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a32887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "X_test = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0aa2342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataset and dataloader\n",
    "#ds_train = TensorDataset(X_train, y_train)\n",
    "#train_loader = DataLoader(ds_train, batch_size=10000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05d6c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_test = TensorDataset(X_test, y_test)\n",
    "#test_loader = DataLoader(ds_test, batch_size=10000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92f484ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd597c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super(Net, self).__init__()\n",
    "        if name:\n",
    "            self.name = name\n",
    "        self.fc1 = nn.Linear(30, 28)\n",
    "        self.fc2 = nn.Linear(28, 27)\n",
    "        self.fc3 = nn.Linear(27, 22)\n",
    "        self.fc4 = nn.Linear(22, 19)\n",
    "        self.fc5 = nn.Linear(19, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # compute the total number of parameters\n",
    "        total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        print(self.name + ': total params:', total_params)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a1b0829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, y, criterion, optimizer, num_epochs=25):\n",
    "    start = time.time()\n",
    "    best_loss = float('inf')\n",
    "    best_model = model\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_model = model\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % int(num_epochs / 20) == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.8f}')\n",
    "\n",
    "    print(f'Finished Training, best model with loss: {loss.item():.8f}')\n",
    "    model = best_model\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "    print('training time ', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b043df1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN 28-27-22-19: total params: 2724\n"
     ]
    }
   ],
   "source": [
    "net = Net('NN 28-27-22-19').to(device)\n",
    "#net = torch.load('model_after_run_nn.pth')\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74a114b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10000/200000], Loss: 0.31373087\n",
      "Epoch [20000/200000], Loss: 0.22174183\n",
      "Epoch [30000/200000], Loss: 0.17339225\n",
      "Epoch [40000/200000], Loss: 0.14635111\n",
      "Epoch [50000/200000], Loss: 0.12811467\n",
      "Epoch [60000/200000], Loss: 0.11615847\n",
      "Epoch [70000/200000], Loss: 0.10714879\n",
      "Epoch [80000/200000], Loss: 0.09962326\n",
      "Epoch [90000/200000], Loss: 0.09197962\n",
      "Epoch [100000/200000], Loss: 0.08643211\n",
      "Epoch [110000/200000], Loss: 0.08132211\n",
      "Epoch [120000/200000], Loss: 0.07647118\n",
      "Epoch [130000/200000], Loss: 0.07499529\n",
      "Epoch [140000/200000], Loss: 0.06889779\n",
      "Epoch [150000/200000], Loss: 0.06591066\n",
      "Epoch [160000/200000], Loss: 0.06397809\n",
      "Epoch [170000/200000], Loss: 0.06043433\n",
      "Epoch [180000/200000], Loss: 0.05814252\n",
      "Epoch [190000/200000], Loss: 0.05612484\n",
      "Epoch [200000/200000], Loss: 0.05452114\n",
      "Finished Training, best model with loss: 0.05452114\n",
      "training time  206.20473766326904\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-8)\n",
    "train_model(net, X_train, y_train, criterion, optimizer, num_epochs=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "becfb4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50000/1000000], Loss: 0.04907920\n",
      "Epoch [100000/1000000], Loss: 0.04556113\n",
      "Epoch [150000/1000000], Loss: 0.04276644\n",
      "Epoch [200000/1000000], Loss: 0.04049289\n",
      "Epoch [250000/1000000], Loss: 0.03859017\n",
      "Epoch [300000/1000000], Loss: 0.03666690\n",
      "Epoch [350000/1000000], Loss: 0.03500682\n",
      "Epoch [400000/1000000], Loss: 0.03352980\n",
      "Epoch [450000/1000000], Loss: 0.03259426\n",
      "Epoch [500000/1000000], Loss: 0.03199252\n",
      "Epoch [550000/1000000], Loss: 0.03138289\n",
      "Epoch [600000/1000000], Loss: 0.03087592\n",
      "Epoch [650000/1000000], Loss: 0.03047173\n",
      "Epoch [700000/1000000], Loss: 0.03012018\n",
      "Epoch [750000/1000000], Loss: 0.02972123\n",
      "Epoch [800000/1000000], Loss: 0.02938945\n",
      "Epoch [850000/1000000], Loss: 0.02904428\n",
      "Epoch [900000/1000000], Loss: 0.02868572\n",
      "Epoch [950000/1000000], Loss: 0.02825257\n",
      "Epoch [1000000/1000000], Loss: 0.02798982\n",
      "Finished Training, best model with loss: 0.02798982\n",
      "training time  1026.2480957508087\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.0001, weight_decay=1e-8)\n",
    "train_model(net, X_train, y_train, criterion, optimizer, num_epochs=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c612c9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the training set: 0.9842\n",
      "Confusion Matrix:\n",
      "[[2276   58]\n",
      " [  45 4150]]\n"
     ]
    }
   ],
   "source": [
    "# Predict the values\n",
    "net.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    y_pred = net(X_train).cpu()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(np.sign(y_train.cpu()), np.sign(y_pred))\n",
    "print(f'Accuracy for the training set: {accuracy:.4f}')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(np.sign(y_train.cpu()), np.sign(y_pred))\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6778b726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the testing set: 0.9510\n",
      "Confusion Matrix:\n",
      "[[ 536   49]\n",
      " [  31 1017]]\n"
     ]
    }
   ],
   "source": [
    "# Predict the values\n",
    "net.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    y_pred = net(X_test).cpu()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(np.sign(y_test.cpu()), np.sign(y_pred))\n",
    "print(f'Accuracy for the testing set: {accuracy:.4f}')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(np.sign(y_test.cpu()), np.sign(y_pred))\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ca941b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'model_after_run_nn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f81a94",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The fact that the model guesses the direction of the market movement in 95 cases out of a hundred on the test data set is phenomenal. The good news is that on the training data set this value is 98%, which indicates that the model was not overfitted and it has a reasonable degree of generalization.\n",
    "It would be interesting to see the potential ROI of a trading machine if it is buid on such predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3156fa",
   "metadata": {},
   "source": [
    "### Add prediction to the SP500 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89d4ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = pd.read_excel('sp500.xlsx', parse_dates=[0], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8bc667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(X_)\n",
    "X = torch.tensor(X_scaled, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa3ba371",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500['Prediction'] = net(X).cpu().detach().numpy()/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34017836",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500.to_excel('sp500.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f98ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
